# â±ğŸ“Š Time Series Forecasting with Machine Learning

This project focuses on forecasting **hourly taxi demand** using historical data while strictly respecting the time dimension to prevent data leakage and ensure realistic model evaluation.

---

## ğŸ·ï¸ Tech Stack
Python Â· pandas Â· NumPy Â· scikit-learn Â· Matplotlib Â· Jupyter Notebook

---

## ğŸ“‘ Table of Contents
1. ğŸ¯ Problem Statement  
2. ğŸ¯ Project Goals  
3. ğŸ§¾ Dataset Overview  
4. ğŸ§  Approach & Methodology  
5. ğŸ“Š Evaluation & Metrics  
6. ğŸ§° Tools & Libraries  
7. â–¶ï¸ How to Run the Project  
8. ğŸ“ Project Structure  
9. ğŸ’¡ Key Takeaways  
10. ğŸš€ Next Steps & Improvements  
11. ğŸ‘¤ Author & Connect  

---

## ğŸ¯ 01 â€” Problem Statement
Accurately forecast future values in time-dependent data while preserving chronological order and avoiding data leakage that could inflate model performance.

---

## ğŸ¯ 02 â€” Project Goals
- Identify temporal patterns and seasonality in hourly taxi demand  
- Engineer time-based features such as lag values and rolling statistics  
- Train and evaluate forecasting models using time-aware validation  
- Compare model performance against a naive baseline  

---

## ğŸ§¾ 03 â€” Dataset Overview
- Hourly time-indexed observations  
- Target variable: `num_orders`  
- Data resampled to hourly frequency  
- Chronological ordering preserved throughout the analysis  

A small sample dataset is included in `data/sample/` to allow the project to run without access to the full dataset.

---

## ğŸ§  04 â€” Approach & Methodology
This project follows a leakage-free time series workflow:

**Exploratory Data Analysis (EDA)**
- Visualized hourly demand to identify trends and seasonality  

**Feature Engineering**
- Lag features for the previous 1â€“24 hours  
- Rolling mean features using 3, 6, 12, and 24-hour windows  
- Calendar features including hour of day and day of week  

**Train/Test Split**
- Time-based split without shuffling  
- Ensures future data is never used to predict the past  

---

## ğŸ“Š 05 â€” Evaluation & Metrics
Models were evaluated using **Root Mean Squared Error (RMSE)**.

| Model | RMSE |
|------|------|
| Baseline (lag-1) | ~29.29 |
| Linear Regression | ~20.45 |
| Random Forest | ~20.68 |

Linear Regression achieved the lowest RMSE, significantly outperforming the baseline model and demonstrating the impact of feature engineering on short-term forecasting.

---

## ğŸ§° 06 â€” Tools & Libraries
- Python  
- pandas  
- NumPy  
-  -learn  
- Matplotlib  

---

## â–¶ï¸ 07 â€” How to Run the Project
1. Open `Sprint13_Time_Series.ipynb`
2. Run all cells from top to bottom  
3. Ensure the sample dataset exists at:

---

## ğŸ“ 08 â€” Project Structure
Sprint13_Time_Series/
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ sample/
â”‚ â””â”€â”€ taxi_sample.csv
â”‚
â”œâ”€â”€ Sprint13_Time_Series.ipynb
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore


---

## ğŸ’¡ 09 â€” Key Takeaways
- Time-aware validation is critical for forecasting tasks  
- Simple models can outperform complex ones with strong feature engineering  
- Baseline models provide essential context for evaluating performance  
- Model selection should balance accuracy, interpretability, and practicality  

---

## ğŸš€ 10 â€” Next Steps & Improvements
- Hyperparameter tuning for tree-based models  
- Feature selection to reduce multicollinearity  
- Evaluation on longer forecasting horizons  
- Production-style inference and monitoring  

---

## ğŸ‘¤ 11 â€” Author & Connect
**Tamauri Olive**  
Aspiring Wellness Data Scientist â€” blending AI, empathy, and impact  

ğŸ”— LinkedIn: www.linkedin.com/in/tamauri-olive-499845113  
ğŸ”— GitHub: https://github.com/Olivenatural
